{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "meeting_6.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mr94t3z/pembelajaran-mesin/blob/master/meeting_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree\n",
        "\n",
        "https://towardsdatascience.com/everything-you-ever-wanted-to-know-about-decision-trees-in-python-17e8edb6b37b"
      ],
      "metadata": {
        "id": "ksJfI3ipWzsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import graphviz\n",
        "import pydotplus\n",
        "import matplotlib.image as mpimg\n",
        "import io\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import preprocessing, tree, datasets\n",
        "!pip install dtreeviz\n",
        "#from dtreeviz.trees import dtreeviz\n",
        "\n",
        "pd.set_option('display.max_rows', 10)\n",
        "random.seed(24)"
      ],
      "metadata": {
        "id": "NoEszv3yW0-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_red_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
        "df_white_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')\n",
        "\n",
        "df_red_wine['label'] = 1\n",
        "df_white_wine['label'] = 0\n",
        "\n",
        "df_merged_wine = pd.concat([df_red_wine, df_white_wine])\n",
        "df_merged_wine"
      ],
      "metadata": {
        "id": "_tgZqT5bY3qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_white_wine.head()"
      ],
      "metadata": {
        "id": "UNp5bJzUZLRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged_wine['label'].value_counts(normalize=True)\n",
        "\n",
        "# tidak seimbang label 0 dan 1 nya"
      ],
      "metadata": {
        "id": "ZtJrdCpfaNNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# down-sampling commonly technique to balancing the dataset\n",
        "\n",
        "red_wines = df_merged_wine[df_merged_wine['label'] == 1]\n",
        "all_white_wines = df_merged_wine[df_merged_wine['label'] == 0]\n",
        "\n",
        "white_wines = all_white_wines.sample(n=red_wines.shape[0], random_state=24)\n",
        "\n",
        "df_wine_balanced = pd.concat([red_wines, white_wines])\n",
        "\n",
        "df_wine_balanced"
      ],
      "metadata": {
        "id": "rP5NrFSaaa6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_wine_balanced['label'].value_counts(normalize=True)\n",
        "\n",
        "# dataset sudah balance"
      ],
      "metadata": {
        "id": "O2q_Nucpdafc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pembagian data train dan test\n",
        "\n",
        "X = df_wine_balanced.drop('label', axis=1)\n",
        "y = df_wine_balanced['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24)"
      ],
      "metadata": {
        "id": "TqJR0qbSdjL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning the Model\n",
        "\n",
        "def dtree_grid_search(X, y, nfolds):\n",
        "\n",
        "    param_grid = {'criterion':['gini','entropy'], \n",
        "                  'class_weight':['balanced',None], \n",
        "                  'splitter':['best','random'], \n",
        "                  'max_features':['auto', 'sqrt', 'log2', None], \n",
        "                  'max_depth': np.arange(3, 15)}\n",
        "\n",
        "    dtree_model=DecisionTreeClassifier(random_state=24)\n",
        "    dtree_gscv = GridSearchCV(dtree_model, param_grid, cv=nfolds)\n",
        "    dtree_gscv.fit(X, y)\n",
        "    \n",
        "    return pd.DataFrame(dtree_gscv.best_params_, index=['Value']).T\n",
        "\n",
        "dtree_grid_search(X_train, y_train, 10)"
      ],
      "metadata": {
        "id": "vlljBkkld4bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Decision Tree Model\n",
        "\n",
        "classifier = tree.DecisionTreeClassifier(class_weight=None, \n",
        "                                         criterion='entropy', \n",
        "                                         max_depth=3,\n",
        "                                         max_features='auto', \n",
        "                                         splitter='best', \n",
        "                                         random_state=24)\n",
        "model = classifier.fit(X_train, y_train)\n",
        "model.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "t1mVOOLReeCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance\n",
        "\n",
        "features_dict = {'feature_importances': classifier.feature_importances_, 'feature_names': X_train.columns}\n",
        "\n",
        "pd.DataFrame(features_dict).sort_values(by='feature_importances', ascending=False).head(10)"
      ],
      "metadata": {
        "id": "jOXlDNMMeuXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising the Decision Tree\n",
        "!pip install dtreeviz \n",
        "from dtreeviz.trees import dtreeviz\n",
        "viz = dtreeviz(classifier, \n",
        "               X_train, \n",
        "               y_train,\n",
        "               target_name='label',\n",
        "               feature_names=X.columns.to_list(), \n",
        "               class_names=[\"red\", \"white\"],\n",
        "               scale=1.4)\n",
        "\n",
        "viz.save(\"dtreeviz.svg\")\n",
        "\n",
        "viz"
      ],
      "metadata": {
        "id": "hwb_-MOee2jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dot_data = io.StringIO()\n",
        "tree.export_graphviz(classifier, out_file=dot_data, \n",
        "                     feature_names=X.columns.to_list(),  \n",
        "                     filled=True,\n",
        "                     class_names=['red', 'white'],\n",
        "                     rounded=True)\n",
        "\n",
        "filename = \"graphviz.png\"\n",
        "pydotplus.graph_from_dot_data(dot_data.getvalue()).write_png(filename)\n",
        "\n",
        "plt.figure(figsize=(25,10))\n",
        "plt.box(False)\n",
        "\n",
        "img = mpimg.imread(filename)\n",
        "fig = plt.imshow(img)\n",
        "fig.axes.get_xaxis().set_visible(False)\n",
        "fig.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c_SfbfvYhXP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the Model to Make Predictions\n",
        "\n",
        "def predict_single_label(fixed_acidity, \n",
        "                         volatile_acidity, \n",
        "                         citric_acid, \n",
        "                         residual_sugar, \n",
        "                         chlorides, \n",
        "                         free_sulfur_dioxide, \n",
        "                         total_sulfur_dioxide, \n",
        "                         density, \n",
        "                         pH, \n",
        "                         suplhates, \n",
        "                         alcohol, \n",
        "                         quality):\n",
        "    y_predict = classifier.predict([[fixed_acidity, volatile_acidity, citric_acid, residual_sugar, chlorides, free_sulfur_dioxide, total_sulfur_dioxide, density, pH, suplhates, alcohol, quality]])[0]\n",
        "    return \"red\" if y_predict == 1 else \"white\""
      ],
      "metadata": {
        "id": "xIptFHkfhzIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_wine_balanced.head(1)\n",
        "df_wine_balanced.tail(1)"
      ],
      "metadata": {
        "id": "HJ_wiXdNh2tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = predict_single_label(7.4, 0.7, 0.0, 1.9, 0.076, 11.0, 34.0, 0.9978, 3.51, 0.56, 9.4, 5)\n",
        "test2 = predict_single_label(6.9, 0.32, 0.17, 7.6, 0.042, 69.0, 219.0, 0.9959, 3.13, 0.4, 8.9, 5)\n",
        "test1, test2"
      ],
      "metadata": {
        "id": "h4VKkXUciD5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# another prediction\n",
        "\n",
        "df_predictions = X_test.copy()\n",
        "df_predictions['label'] = y_test\n",
        "df_predictions['predicted_label'] = classifier.predict(X_test)\n",
        "\n",
        "df_predictions"
      ],
      "metadata": {
        "id": "n9WW964JiLhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_correct = df_predictions['label'] == df_predictions['predicted_label']\n",
        "df_predictions_correct = df_predictions.loc[filter_correct]\n",
        "\n",
        "calc_score = len(df_predictions.loc[filter_correct]) / len(df_predictions)\n",
        "model_score = model.score(X_test, y_test)\n",
        "\n",
        "calc_score, model_score"
      ],
      "metadata": {
        "id": "9H1uMyL5i4x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deploy model to production\n",
        "\n",
        "text_representation = tree.export_text(classifier, feature_names=X.columns.to_list())\n",
        "print(text_representation)"
      ],
      "metadata": {
        "id": "RzuqM5g3jEKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Classification\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/"
      ],
      "metadata": {
        "id": "hB9IgET11j21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "9uJ6Pdkv1odL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the csv file and putting it into 'df' object\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Mr94t3z/pembelajaran-mesin/master/datasets/heart_v2.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "hyQKiQ6F1sp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting feature variable to X\n",
        "X = df.drop('heart disease',axis=1)\n",
        "# Putting response variable to y\n",
        "y = df['heart disease']"
      ],
      "metadata": {
        "id": "XktWAmfU2IgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "znYMC0kZ2QVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier_rf = RandomForestClassifier(\n",
        "    random_state=42, \n",
        "    n_jobs=-1, \n",
        "    max_depth=5,\n",
        "    n_estimators=100, \n",
        "    oob_score=True\n",
        "    )\n",
        "\n",
        "classifier_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "uECKqydl2gND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_rf.oob_score_"
      ],
      "metadata": {
        "id": "d4bB4lKu2504"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter tuning for Random Forest using GridSearchCV and fit the data\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "params = {\n",
        "    'max_depth': [2,3,5,10,20],\n",
        "    'min_samples_leaf': [5,10,20,50,100,200],\n",
        "    'n_estimators': [10,25,30,50,100,200]\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=params,\n",
        "    cv = 4,\n",
        "    n_jobs=-1,\n",
        "    verbose=1, \n",
        "    scoring=\"accuracy\"\n",
        "    )\n",
        "\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "-WWkvXSl3dO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_score_"
      ],
      "metadata": {
        "id": "0gBvLm-t4Lk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_best = grid_search.best_estimator_\n",
        "rf_best"
      ],
      "metadata": {
        "id": "Ce_k8Wd-4Y2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "plt.figure(figsize=(80,40))\n",
        "plot_tree(rf_best.estimators_[5], feature_names = X.columns,class_names=['Disease', \"No Disease\"],filled=True);"
      ],
      "metadata": {
        "id": "k4gig9yy4xfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imp_df = pd.DataFrame({\n",
        "    \"Varname\": X_train.columns,\n",
        "    \"Imp\": rf_best.feature_importances_\n",
        "})\n",
        "\n",
        "imp_df.sort_values(by=\"Imp\", ascending=False)"
      ],
      "metadata": {
        "id": "rJsdT77v6tSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Nearest Neighbor\n",
        "\n",
        "https://towardsdatascience.com/multiclass-classification-using-k-nearest-neighbours-ca5281a9ef76\n",
        "\n",
        "https://medium.com/geekculture/k-nearest-neighbors-a-to-z-with-implementation-in-python-74630ffb79a2#:~:text=K%2DNearest%20Neighbors%20(kNN)%20is%20a%20Machine%20Learning%20algorithm,and%20simple%20Machine%20Learning%20algorithms."
      ],
      "metadata": {
        "id": "kmmUis9k7TbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8jyX-0vD7cP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the csv file and putting it into 'df' object\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Mr94t3z/pembelajaran-mesin/master/datasets/iris.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ATel4g5i_3wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['variety'].unique()"
      ],
      "metadata": {
        "id": "0XMJl38VAWjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().values.any()"
      ],
      "metadata": {
        "id": "cOFhivhjAd4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['variety'] = df['variety'].map({'Setosa' :0, 'Versicolor' :1, 'Virginica' :2}).astype(int) #mapping numbers\n",
        "df.head()"
      ],
      "metadata": {
        "id": "XiiIKWF7AhdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.close();\n",
        "sns.set_style('whitegrid');\n",
        "sns.pairplot(df, hue='variety', height=3);\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7iozk-MtBMr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid');\n",
        "sns.FacetGrid(df, hue='variety', size=5) \\\n",
        ".map(plt.scatter, 'sepal.length', 'sepal.width') \\\n",
        ".add_legend();\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e1BHJE-qB4Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the EDA and before training our model on the dataset, the one last thing left to do is normalisation. Normalisation is basically bringing all the values of different features on a same scale. As different features has different scale, normalising helps us and the model to optimise itâ€™s parameters more efficiently. We normalise all our input from scale: 0 to 1. Here, X is our inputs(hence dropping the classified species) and Y is our output(3 classes)."
      ],
      "metadata": {
        "id": "HSviUKG9CjUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = df.drop(['variety'],axis=1)\n",
        "y_data = df['variety']\n",
        "MinMaxScaler = preprocessing.MinMaxScaler()\n",
        "X_data_minmax = MinMaxScaler.fit_transform(x_data)\n",
        "data = pd.DataFrame(X_data_minmax,columns=['sepal.length', 'sepal.width', 'petal.length', 'petal.width'])\n",
        "df.head(100)"
      ],
      "metadata": {
        "id": "tVW3bH3iCkSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, y_data,test_size=0.2, random_state = 1)\n",
        "knn_clf=KNeighborsClassifier()\n",
        "knn_clf.fit(X_train,y_train)\n",
        "ypred=knn_clf.predict(X_test)\n",
        "ypred"
      ],
      "metadata": {
        "id": "mrFcouGeD1BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(knn_clf.predict([[0.416667, 0.833333, 0.033898, 0.041667]]))"
      ],
      "metadata": {
        "id": "i_2MZQ-ZFXiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "result = confusion_matrix(y_test, ypred)\n",
        "print('Confusion Matrix:')\n",
        "print(result)\n",
        "result1 = classification_report(y_test, ypred)\n",
        "print('Classification Report:',)\n",
        "print (result1)\n",
        "result2 = accuracy_score(y_test,ypred)\n",
        "print('Accuracy:',result2)"
      ],
      "metadata": {
        "id": "Cxf6Py5kEDwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "n_neighbors = 15\n",
        "\n",
        "evals = []\n",
        "for n_neighbors in range(1, 30, 2):\n",
        "    clf = KNeighborsClassifier(n_neighbors)\n",
        "    clf.fit(X_train, y_train) \n",
        "    score = accuracy_score(clf.predict(X_train), y_train)\n",
        "    evals.append({'k': n_neighbors, 'accuracy': score})\n",
        "\n",
        "\n",
        "evals = pd.DataFrame(evals)\n",
        "best_k = evals.sort_values(by='accuracy', ascending=False).iloc[0]\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.plot(evals['k'], evals['accuracy'], lw=3, c='#087E8B')\n",
        "plt.scatter(best_k['k'], best_k['accuracy'], s=200, c='#087E8B')\n",
        "plt.title(f\"K Parameter Optimization, Optimal k = {int(best_k['k'])}\", size=20)\n",
        "plt.xlabel('K', size=14)\n",
        "plt.ylabel('Accuracy', size=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SLLXS250GXY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826"
      ],
      "metadata": {
        "id": "hfQYw-KyMlIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "ckXY806rI2IC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_wine_balanced"
      ],
      "metadata": {
        "id": "I7ZWXfJMI4Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variabel independen\n",
        "x = df_wine_balanced.drop([\"label\"], axis = 1)\n",
        "x.head()\n",
        "# Variabel dependen\n",
        "y = df_wine_balanced[\"label\"]\n",
        "y.head()"
      ],
      "metadata": {
        "id": "RSdHwi7KPDEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 123)"
      ],
      "metadata": {
        "id": "qINB3OV-PMfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Mengaktifkan/memanggil/membuat fungsi klasifikasi Naive Bayes Gaussian\n",
        "modelnb = GaussianNB()\n",
        "# Memasukkan data training pada fungsi klasifikasi Naive Bayes\n",
        "nbtrain = modelnb.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "M4WOslzlPhkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan hasil prediksi dari x_test\n",
        "y_pred = nbtrain.predict(x_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "ST9YfSldPnm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y_test)"
      ],
      "metadata": {
        "id": "4Ev5k0DVPsF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Menentukan probabilitas hasil prediksi\n",
        "nbtrain.predict_proba(x_test)"
      ],
      "metadata": {
        "id": "fvRZtINHP1B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "SWRe1T0-P7zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "8PhTCKHWQG8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# confusion matrix with multiple class ML\n",
        "\n",
        "https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826"
      ],
      "metadata": {
        "id": "Vs9j2OuoRvPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing a 3-class dataset from sklearn's toy dataset\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "dataset = load_wine()\n",
        "X = dataset.data\n",
        "y = dataset.target\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "svc = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "#importing confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "\n",
        "#importing accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
        "\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
        "\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(y_test, y_pred, target_names=['Class 1', 'Class 2', 'Class 3']))"
      ],
      "metadata": {
        "id": "rEFh1_8YdRSy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}